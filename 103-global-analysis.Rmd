---
title: "103-global-analysis"
output: html_document
date: "2024-04-02"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning=FALSE, message=FALSE)
```

```{r}
library(tidyverse)
```

We can try to generate a phylogenetic network of all our samples.   

We need to be identify key lineages.    

We also need to account for heterogeneity in coverage by downsampling to a certain threshold.   


Our key lineages are Eremichthys, Siphateles.

May not have euchila, from Hubbs and Miller (1972), Fish Creek Spring, Fish Creek Valley, White Pine Co., NV (synonym of newarkensis)
species:   
mohavensis (no subs)
isolatata (no subs)
newarkensis (newarkensis, euchila)
thalassinus (thalassinus, vaccaceps)
bicolor (bicolor, columbianus, eurysoma, 'Silver Lake Valley')
obesus (obesus, snyderi, oregonensis, pectinifer)
'toikona'?

```{r}
m<-read_csv("meta/04032023-edited.csv") %>% mutate(Path=paste0("data/align/",Ind,".sort.flt.bam"))
m
```

```{r}
m5<-m %>% filter(Dedup>5e5)
m5 %>% select(Path) %>% write_tsv("bamlists/test1124.bamlist", col_names = FALSE)
m5 %>% group_by(Species) %>% summarize(Count=n())
```

We should be able to sort these rapidly into
(1) Eremichthys
(2) Siphateles 

1124 samples.  Using angsd with 24 processors and 128 G mem like so:

```{sh, eval=FALSE}
srun -p bigmemh -t 36:00:00 --mem=128G --nodes=1 --ntasks=1 --cpus-per-task=24  $HOME/angsd/angsd -P 24  \
-bam bamlists/test1124.bamlist -ref /home/maccamp/genomes/gila-orcutti/GCA_026230005.1_fGilOrc1.0.hap1_genomic.fna.gz \
-minInd 1012 -minMapQ 10 -minQ 20 -GL 2 -doGLF 2 \
-doMajorMinor 1 -doMaf 1 -SNP_pval 1e-6 \
-doIBS 1 -doCounts 1 -doCov 1 -makeMatrix 1 -minMaf 0.05 \
-out outputs/103/test1124-ibs-90 >outputs/103/test1124-ibs-90.out 2> outputs/103/test1124-ibs-90.err &

srun -p bigmemh -t 36:00:00 --mem=128G --nodes=1 --ntasks=1 --cpus-per-task=12  $HOME/angsd/angsd -P 12  \
-bam bamlists/test1124.bamlist -ref /home/maccamp/genomes/gila-orcutti/GCA_026230005.1_fGilOrc1.0.hap1_genomic.fna.gz \
-minInd 1012 -minMapQ 10 -minQ 20 -GL 2 -doGLF 2 \
-doMajorMinor 1 -doMaf 1 -SNP_pval 1e-6 \
-doIBS 1 -doCounts 1 -doCov 1 -makeMatrix 1 -minMaf 0.05 \
-out outputs/103/test1124-12cpu-ibs-90 >outputs/103/test1124-12cpu-ibs-90.out 2> outputs/103/test1124-12cpu-ibs-90.err &

```


May have to split into regions and separate jobs here for SNP calling.     
```{r}
m %>% filter(Dedup > 1e6) %>% group_by(Species) %>% summarize(Count=n())
```

Downsample.

```{r}
ggplot(m) +
  geom_histogram(aes(x=Dedup)) +
  theme_bw() +
  ylab("Count\n") +
  xlab("\nPost PCR Duplication") +
  theme(panel.grid=element_blank())

```

```{r}
mean(m$Dedup)
median(m$Dedup)
```

```{r}
m %>% filter(Dedup>1e6) %>% summarize(Mean=mean(Dedup), Median=median(Dedup))
```
Downsample to 2e6 reads, 543 ind downsampled.

What I think may work is to:

(1) use >1e6 inds for SNP calls, define major groups
(2) use >5e5 inds for GLs, for pop gen analyses (e.g. with doIbs)



```{r}
down<-m %>%  mutate(Frac=2e6/Dedup)  %>% 
  mutate(Path2=ifelse(Dedup > 2e6, paste0("data/downsample/",Ind,".reduced.bam"),
                     Path))

downsample<-down %>% filter(Dedup > 2e6 ) %>%
  mutate(ReductionCommand = paste0("samtools view -bs ",Frac, " ", Path," > ",
                                   Path2)) 

write_csv(downsample$ReductionCommand %>% as_tibble(), "103.1-downsample.sh", col_names = FALSE)

write_csv(down, "meta/downsampled-paths-meta.csv")
```

544
Downsampling    
```{sh, eval=FALSE}
module load parallel
srun -p high -t 04:00:00 --nodes=1 parallel -j 10 < 103.1-downsample.sh > outputs/103/downsample.stdout 2> outputs/103/downsample.stderr
```

```{r}
million<-down %>% filter(Dedup>1e6)
million %>% select(Path2) %>% write_tsv("bamlists/test921.bamlist", col_names = FALSE)
million %>% select(GVL_Code) %>% write_tsv("bamlists/test921.names", col_names = FALSE)
million %>% group_by(Species) %>% summarize(Count=n(), MeanReadCounts=mean(Dedup))
```


Ok, now we can do some snp calls and see what shakes out.   
95% threshold.       
```{sh, eval=FALSE}
srun -t 36:00:00 -p bigmemh --mem=128G --nodes=1 --ntasks-per-node=1 --cpus-per-task=12 $HOME/angsd/angsd -nthreads 24 \
-minInd 875 -bam bamlists/test921.bamlist -ref /home/maccamp/genomes/gila-orcutti/GCA_026230005.1_fGilOrc1.0.hap1_genomic.fna.gz \
-out outputs/103/snps-921  \
-minMaf 0.05 -minMapQ 20 -minQ 20 -GL 1 -doMajorMinor 1 -doMaf 1 -SNP_pval 1e-6 \
-doGeno 2 -doPost 1 -postCutoff 0.95 -doPlink 2  > outputs/103/snps-921.out 2> outputs/103/snps-921.err &
```

Creating a vcf

```{sh, eval=FALSE}
plink --tped snps-921.tped --tfam snps-921.tfam  --out plink-binary --recode --allow-extra-chr --noweb
plink --ped plink-binary.ped --map plink-binary.map --recode vcf --allow-extra-chr -out plink
bgzip plink.vcf 
tabix plink.vcf.gz

#renaming vcf with GVL_Code
bcftools reheader --samples bamlists/test921.names -o outputs/103/renamed.vcf.gz outputs/103/plink.vcf.gz

bcftools +prune -l 0.20 -w 10000 outputs/103/renamed.vcf.gz > outputs/103/pruned.vcf
bcftools +prune -l 0.30 -w 10000 outputs/103/renamed.vcf.gz > outputs/103/pruned-03.vcf
```


THen we can try making a nexus file and a NJ tree/network. 